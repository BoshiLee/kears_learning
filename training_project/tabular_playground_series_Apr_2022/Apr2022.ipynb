{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004fb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdad0901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\keras_learning\\training_project\\tabular_playground_series_Apr_2022\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c4d65",
   "metadata": {},
   "source": [
    "In this competition, you'll classify 60-second sequences of sensor data, indicating whether a subject was in either of two activity states for the duration of the sequence.\n",
    "\n",
    "在本次競賽中，您將對 60 秒的感測器資料序列進行分類，找出受試者在序列持續時間內處於兩種活動狀態的其中一種。\n",
    "\n",
    "## Files and Field Descriptions\n",
    "- train.csv - the training set, comprising ~26,000 60-second recordings of thirteen biological sensors for almost one thousand experimental participants\n",
    "    - sequence - a unique id for each sequence\n",
    "    - subject - a unique id for the subject in the experiment\n",
    "    - step - time step of the recording, in one second intervals\n",
    "    - sensor_00 - sensor_12 - the value for each of the thirteen sensors at that time step\n",
    "- train_labels.csv - the class label for each sequence.\n",
    "    - sequence - the unique id for each sequence.\n",
    "    - state - the state associated to each sequence. This is the target which you are trying to predict.\n",
    "- test.csv - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state.\n",
    "- sample_submission.csv - a sample submission file in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "         sequence  subject  step  sensor_00  sensor_01  sensor_02  sensor_03  \\\n0               0       47     0  -0.196291   0.112395   1.000000   0.329204   \n1               0       47     1  -0.447450   0.134454   1.000000  -0.658407   \n2               0       47     2   0.326893  -0.694328   1.000000   0.330088   \n3               0       47     3   0.523184   0.751050   1.000000   0.976991   \n4               0       47     4   0.272025   1.074580   1.000000  -0.136283   \n...           ...      ...   ...        ...        ...        ...        ...   \n1558075     25967      327    55  -0.282844  -1.217437  -1.666153   0.586726   \n1558076     25967      327    56   0.130603   0.349790  -1.666153  -0.324779   \n1558077     25967      327    57  -0.579598   0.429622  -1.666153   0.319469   \n1558078     25967      327    58   1.278980   1.711134  -1.522820   0.802655   \n1558079     25967      327    59  -1.136012  -3.702731  -1.332820  -0.766372   \n\n         sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n0        -1.004660  -0.131638  -0.127505   0.368702       -0.1  -0.963873   \n1         0.162495   0.340314  -0.209472  -0.867176        0.2  -0.301301   \n2         0.473678   1.280479  -0.094718   0.535878        1.4   1.002168   \n3        -0.563287  -0.720269   0.793260   0.951145       -0.3  -0.995665   \n4         0.398579   0.044877   0.560109  -0.541985       -0.9   1.055636   \n...            ...        ...        ...        ...        ...        ...   \n1558075  -0.930698  -0.451010  -0.651184   0.368702        0.4   0.008671   \n1558076   0.775324  -0.332835   0.099271   0.122137       -0.2   0.644509   \n1558077   0.308861   0.282723  -0.512750   0.012214       -1.6  -0.424133   \n1558078  -0.460541  -0.055348   2.405282   0.043511        1.9   0.283960   \n1558079  -0.430027  -0.091997  -2.512750  -0.022901       -1.1  -0.653902   \n\n         sensor_10  sensor_11  sensor_12  \n0        -0.985069   0.531893   4.751492  \n1         0.082733  -0.231481   0.454390  \n2         0.449221  -0.586420  -4.736147  \n3        -0.434290   1.344650   0.429241  \n4         0.812631   0.123457  -0.223359  \n...            ...        ...        ...  \n1558075  -0.723536  -0.353909  -0.914749  \n1558076   0.691407  -0.613169  -0.515772  \n1558077   0.716855   1.628601   0.928389  \n1558078  -0.914914   0.364198   0.211424  \n1558079  -0.418516  -1.453704  -1.561381  \n\n[1558080 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>subject</th>\n      <th>step</th>\n      <th>sensor_00</th>\n      <th>sensor_01</th>\n      <th>sensor_02</th>\n      <th>sensor_03</th>\n      <th>sensor_04</th>\n      <th>sensor_05</th>\n      <th>sensor_06</th>\n      <th>sensor_07</th>\n      <th>sensor_08</th>\n      <th>sensor_09</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>47</td>\n      <td>0</td>\n      <td>-0.196291</td>\n      <td>0.112395</td>\n      <td>1.000000</td>\n      <td>0.329204</td>\n      <td>-1.004660</td>\n      <td>-0.131638</td>\n      <td>-0.127505</td>\n      <td>0.368702</td>\n      <td>-0.1</td>\n      <td>-0.963873</td>\n      <td>-0.985069</td>\n      <td>0.531893</td>\n      <td>4.751492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>47</td>\n      <td>1</td>\n      <td>-0.447450</td>\n      <td>0.134454</td>\n      <td>1.000000</td>\n      <td>-0.658407</td>\n      <td>0.162495</td>\n      <td>0.340314</td>\n      <td>-0.209472</td>\n      <td>-0.867176</td>\n      <td>0.2</td>\n      <td>-0.301301</td>\n      <td>0.082733</td>\n      <td>-0.231481</td>\n      <td>0.454390</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>47</td>\n      <td>2</td>\n      <td>0.326893</td>\n      <td>-0.694328</td>\n      <td>1.000000</td>\n      <td>0.330088</td>\n      <td>0.473678</td>\n      <td>1.280479</td>\n      <td>-0.094718</td>\n      <td>0.535878</td>\n      <td>1.4</td>\n      <td>1.002168</td>\n      <td>0.449221</td>\n      <td>-0.586420</td>\n      <td>-4.736147</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>47</td>\n      <td>3</td>\n      <td>0.523184</td>\n      <td>0.751050</td>\n      <td>1.000000</td>\n      <td>0.976991</td>\n      <td>-0.563287</td>\n      <td>-0.720269</td>\n      <td>0.793260</td>\n      <td>0.951145</td>\n      <td>-0.3</td>\n      <td>-0.995665</td>\n      <td>-0.434290</td>\n      <td>1.344650</td>\n      <td>0.429241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>47</td>\n      <td>4</td>\n      <td>0.272025</td>\n      <td>1.074580</td>\n      <td>1.000000</td>\n      <td>-0.136283</td>\n      <td>0.398579</td>\n      <td>0.044877</td>\n      <td>0.560109</td>\n      <td>-0.541985</td>\n      <td>-0.9</td>\n      <td>1.055636</td>\n      <td>0.812631</td>\n      <td>0.123457</td>\n      <td>-0.223359</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1558075</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>55</td>\n      <td>-0.282844</td>\n      <td>-1.217437</td>\n      <td>-1.666153</td>\n      <td>0.586726</td>\n      <td>-0.930698</td>\n      <td>-0.451010</td>\n      <td>-0.651184</td>\n      <td>0.368702</td>\n      <td>0.4</td>\n      <td>0.008671</td>\n      <td>-0.723536</td>\n      <td>-0.353909</td>\n      <td>-0.914749</td>\n    </tr>\n    <tr>\n      <th>1558076</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>56</td>\n      <td>0.130603</td>\n      <td>0.349790</td>\n      <td>-1.666153</td>\n      <td>-0.324779</td>\n      <td>0.775324</td>\n      <td>-0.332835</td>\n      <td>0.099271</td>\n      <td>0.122137</td>\n      <td>-0.2</td>\n      <td>0.644509</td>\n      <td>0.691407</td>\n      <td>-0.613169</td>\n      <td>-0.515772</td>\n    </tr>\n    <tr>\n      <th>1558077</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>57</td>\n      <td>-0.579598</td>\n      <td>0.429622</td>\n      <td>-1.666153</td>\n      <td>0.319469</td>\n      <td>0.308861</td>\n      <td>0.282723</td>\n      <td>-0.512750</td>\n      <td>0.012214</td>\n      <td>-1.6</td>\n      <td>-0.424133</td>\n      <td>0.716855</td>\n      <td>1.628601</td>\n      <td>0.928389</td>\n    </tr>\n    <tr>\n      <th>1558078</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>58</td>\n      <td>1.278980</td>\n      <td>1.711134</td>\n      <td>-1.522820</td>\n      <td>0.802655</td>\n      <td>-0.460541</td>\n      <td>-0.055348</td>\n      <td>2.405282</td>\n      <td>0.043511</td>\n      <td>1.9</td>\n      <td>0.283960</td>\n      <td>-0.914914</td>\n      <td>0.364198</td>\n      <td>0.211424</td>\n    </tr>\n    <tr>\n      <th>1558079</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>59</td>\n      <td>-1.136012</td>\n      <td>-3.702731</td>\n      <td>-1.332820</td>\n      <td>-0.766372</td>\n      <td>-0.430027</td>\n      <td>-0.091997</td>\n      <td>-2.512750</td>\n      <td>-0.022901</td>\n      <td>-1.1</td>\n      <td>-0.653902</td>\n      <td>-0.418516</td>\n      <td>-1.453704</td>\n      <td>-1.561381</td>\n    </tr>\n  </tbody>\n</table>\n<p>1558080 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       sequence  state\n0             0      0\n1             1      1\n2             2      1\n3             3      1\n4             4      1\n...         ...    ...\n25963     25963      1\n25964     25964      0\n25965     25965      1\n25966     25966      1\n25967     25967      0\n\n[25968 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25963</th>\n      <td>25963</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25964</th>\n      <td>25964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25965</th>\n      <td>25965</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25966</th>\n      <td>25966</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25967</th>\n      <td>25967</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25968 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "        sequence  subject  step  sensor_00  sensor_01  sensor_02  sensor_03  \\\n0          25968      684     0   2.427357  19.639706    1.00000  -1.466372   \n1          25968      684     1  -4.950541 -21.747899    1.00000   0.983186   \n2          25968      684     2   1.136012 -10.756303    1.00000   1.016814   \n3          25968      684     3   0.806028   6.504202    1.00000  -0.179646   \n4          25968      684     4   1.288253   5.552521    1.00000  -0.493805   \n...          ...      ...   ...        ...        ...        ...        ...   \n733075     38185      773    55   0.211747   2.005252   -1.33282   0.695575   \n733076     38185      773    56  -0.826121  -2.468487   -1.33282   0.381416   \n733077     38185      773    57   0.755023   1.469538   -1.33282  -1.253097   \n733078     38185      773    58  -0.187017   0.714286   -1.33282   0.077876   \n733079     38185      773    59  -0.414992  -2.858193   -1.33282   1.061062   \n\n        sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n0       -1.289973  -4.207928   2.486339  -2.493893        8.0  -1.123555   \n1       -0.569053   1.845924  -3.887978   1.727481       -2.9   0.395231   \n2        0.964157   2.454749   0.312386   1.154198       -5.6   1.114162   \n3        0.969221  -1.035153  -0.457195   0.254962       -2.7  -0.588873   \n4       -1.036124  -1.126402   2.008197  -0.730534        0.0   0.899566   \n...           ...        ...        ...        ...        ...        ...   \n733075  -0.161327  -1.193717   0.421676   0.869466        0.0  -1.536850   \n733076   0.144745   1.060583  -0.765938   0.288550        0.2  -1.956647   \n733077  -0.414802   0.007479   0.907104  -1.556489        0.4   4.341763   \n733078   1.323245   0.159312  -0.397996   0.306870        0.1  -1.013728   \n733079  -0.264150  -0.449514  -0.601093   1.621374       -1.0  -3.650289   \n\n        sensor_10  sensor_11  sensor_12  \n0       -1.673048  10.980453   0.419011  \n1       -0.882233  -1.871399  -0.008525  \n2        1.525273 -11.584362   0.139812  \n3        0.608761  -4.241770  -0.462916  \n4       -1.259615  -0.472222  -0.121483  \n...           ...        ...        ...  \n733075   0.388101   2.205761 -91.610827  \n733076  -0.032158  -1.794239  72.414749  \n733077   0.150273   0.641975 -34.065644  \n733078  -0.608616   0.317901  65.659420  \n733079  -0.147107  -1.559671  57.189685  \n\n[733080 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>subject</th>\n      <th>step</th>\n      <th>sensor_00</th>\n      <th>sensor_01</th>\n      <th>sensor_02</th>\n      <th>sensor_03</th>\n      <th>sensor_04</th>\n      <th>sensor_05</th>\n      <th>sensor_06</th>\n      <th>sensor_07</th>\n      <th>sensor_08</th>\n      <th>sensor_09</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25968</td>\n      <td>684</td>\n      <td>0</td>\n      <td>2.427357</td>\n      <td>19.639706</td>\n      <td>1.00000</td>\n      <td>-1.466372</td>\n      <td>-1.289973</td>\n      <td>-4.207928</td>\n      <td>2.486339</td>\n      <td>-2.493893</td>\n      <td>8.0</td>\n      <td>-1.123555</td>\n      <td>-1.673048</td>\n      <td>10.980453</td>\n      <td>0.419011</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25968</td>\n      <td>684</td>\n      <td>1</td>\n      <td>-4.950541</td>\n      <td>-21.747899</td>\n      <td>1.00000</td>\n      <td>0.983186</td>\n      <td>-0.569053</td>\n      <td>1.845924</td>\n      <td>-3.887978</td>\n      <td>1.727481</td>\n      <td>-2.9</td>\n      <td>0.395231</td>\n      <td>-0.882233</td>\n      <td>-1.871399</td>\n      <td>-0.008525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25968</td>\n      <td>684</td>\n      <td>2</td>\n      <td>1.136012</td>\n      <td>-10.756303</td>\n      <td>1.00000</td>\n      <td>1.016814</td>\n      <td>0.964157</td>\n      <td>2.454749</td>\n      <td>0.312386</td>\n      <td>1.154198</td>\n      <td>-5.6</td>\n      <td>1.114162</td>\n      <td>1.525273</td>\n      <td>-11.584362</td>\n      <td>0.139812</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25968</td>\n      <td>684</td>\n      <td>3</td>\n      <td>0.806028</td>\n      <td>6.504202</td>\n      <td>1.00000</td>\n      <td>-0.179646</td>\n      <td>0.969221</td>\n      <td>-1.035153</td>\n      <td>-0.457195</td>\n      <td>0.254962</td>\n      <td>-2.7</td>\n      <td>-0.588873</td>\n      <td>0.608761</td>\n      <td>-4.241770</td>\n      <td>-0.462916</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25968</td>\n      <td>684</td>\n      <td>4</td>\n      <td>1.288253</td>\n      <td>5.552521</td>\n      <td>1.00000</td>\n      <td>-0.493805</td>\n      <td>-1.036124</td>\n      <td>-1.126402</td>\n      <td>2.008197</td>\n      <td>-0.730534</td>\n      <td>0.0</td>\n      <td>0.899566</td>\n      <td>-1.259615</td>\n      <td>-0.472222</td>\n      <td>-0.121483</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>733075</th>\n      <td>38185</td>\n      <td>773</td>\n      <td>55</td>\n      <td>0.211747</td>\n      <td>2.005252</td>\n      <td>-1.33282</td>\n      <td>0.695575</td>\n      <td>-0.161327</td>\n      <td>-1.193717</td>\n      <td>0.421676</td>\n      <td>0.869466</td>\n      <td>0.0</td>\n      <td>-1.536850</td>\n      <td>0.388101</td>\n      <td>2.205761</td>\n      <td>-91.610827</td>\n    </tr>\n    <tr>\n      <th>733076</th>\n      <td>38185</td>\n      <td>773</td>\n      <td>56</td>\n      <td>-0.826121</td>\n      <td>-2.468487</td>\n      <td>-1.33282</td>\n      <td>0.381416</td>\n      <td>0.144745</td>\n      <td>1.060583</td>\n      <td>-0.765938</td>\n      <td>0.288550</td>\n      <td>0.2</td>\n      <td>-1.956647</td>\n      <td>-0.032158</td>\n      <td>-1.794239</td>\n      <td>72.414749</td>\n    </tr>\n    <tr>\n      <th>733077</th>\n      <td>38185</td>\n      <td>773</td>\n      <td>57</td>\n      <td>0.755023</td>\n      <td>1.469538</td>\n      <td>-1.33282</td>\n      <td>-1.253097</td>\n      <td>-0.414802</td>\n      <td>0.007479</td>\n      <td>0.907104</td>\n      <td>-1.556489</td>\n      <td>0.4</td>\n      <td>4.341763</td>\n      <td>0.150273</td>\n      <td>0.641975</td>\n      <td>-34.065644</td>\n    </tr>\n    <tr>\n      <th>733078</th>\n      <td>38185</td>\n      <td>773</td>\n      <td>58</td>\n      <td>-0.187017</td>\n      <td>0.714286</td>\n      <td>-1.33282</td>\n      <td>0.077876</td>\n      <td>1.323245</td>\n      <td>0.159312</td>\n      <td>-0.397996</td>\n      <td>0.306870</td>\n      <td>0.1</td>\n      <td>-1.013728</td>\n      <td>-0.608616</td>\n      <td>0.317901</td>\n      <td>65.659420</td>\n    </tr>\n    <tr>\n      <th>733079</th>\n      <td>38185</td>\n      <td>773</td>\n      <td>59</td>\n      <td>-0.414992</td>\n      <td>-2.858193</td>\n      <td>-1.33282</td>\n      <td>1.061062</td>\n      <td>-0.264150</td>\n      <td>-0.449514</td>\n      <td>-0.601093</td>\n      <td>1.621374</td>\n      <td>-1.0</td>\n      <td>-3.650289</td>\n      <td>-0.147107</td>\n      <td>-1.559671</td>\n      <td>57.189685</td>\n    </tr>\n  </tbody>\n</table>\n<p>733080 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6539b752",
   "metadata": {},
   "source": [
    "由上表與題目提示可得知，每一秒會記錄一列，每 60 列代表一個 `sequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a76d87",
   "metadata": {},
   "source": [
    "確認資料是否有缺漏，本題的資料都很完美，沒有有缺漏的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ca8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1558080 entries, 0 to 1558079\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   sequence   1558080 non-null  int64  \n",
      " 1   subject    1558080 non-null  int64  \n",
      " 2   step       1558080 non-null  int64  \n",
      " 3   sensor_00  1558080 non-null  float64\n",
      " 4   sensor_01  1558080 non-null  float64\n",
      " 5   sensor_02  1558080 non-null  float64\n",
      " 6   sensor_03  1558080 non-null  float64\n",
      " 7   sensor_04  1558080 non-null  float64\n",
      " 8   sensor_05  1558080 non-null  float64\n",
      " 9   sensor_06  1558080 non-null  float64\n",
      " 10  sensor_07  1558080 non-null  float64\n",
      " 11  sensor_08  1558080 non-null  float64\n",
      " 12  sensor_09  1558080 non-null  float64\n",
      " 13  sensor_10  1558080 non-null  float64\n",
      " 14  sensor_11  1558080 non-null  float64\n",
      " 15  sensor_12  1558080 non-null  float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 190.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b4db6",
   "metadata": {},
   "source": [
    "## 特徵工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857522f",
   "metadata": {},
   "source": [
    "萃取需要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "groups = train['sequence']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "         sequence  subject  step  sensor_00  sensor_01  sensor_02  sensor_03  \\\n0               0       47     0  -0.196291   0.112395   1.000000   0.329204   \n1               0       47     1  -0.447450   0.134454   1.000000  -0.658407   \n2               0       47     2   0.326893  -0.694328   1.000000   0.330088   \n3               0       47     3   0.523184   0.751050   1.000000   0.976991   \n4               0       47     4   0.272025   1.074580   1.000000  -0.136283   \n...           ...      ...   ...        ...        ...        ...        ...   \n1558075     25967      327    55  -0.282844  -1.217437  -1.666153   0.586726   \n1558076     25967      327    56   0.130603   0.349790  -1.666153  -0.324779   \n1558077     25967      327    57  -0.579598   0.429622  -1.666153   0.319469   \n1558078     25967      327    58   1.278980   1.711134  -1.522820   0.802655   \n1558079     25967      327    59  -1.136012  -3.702731  -1.332820  -0.766372   \n\n         sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n0        -1.004660  -0.131638  -0.127505   0.368702       -0.1  -0.963873   \n1         0.162495   0.340314  -0.209472  -0.867176        0.2  -0.301301   \n2         0.473678   1.280479  -0.094718   0.535878        1.4   1.002168   \n3        -0.563287  -0.720269   0.793260   0.951145       -0.3  -0.995665   \n4         0.398579   0.044877   0.560109  -0.541985       -0.9   1.055636   \n...            ...        ...        ...        ...        ...        ...   \n1558075  -0.930698  -0.451010  -0.651184   0.368702        0.4   0.008671   \n1558076   0.775324  -0.332835   0.099271   0.122137       -0.2   0.644509   \n1558077   0.308861   0.282723  -0.512750   0.012214       -1.6  -0.424133   \n1558078  -0.460541  -0.055348   2.405282   0.043511        1.9   0.283960   \n1558079  -0.430027  -0.091997  -2.512750  -0.022901       -1.1  -0.653902   \n\n         sensor_10  sensor_11  sensor_12  \n0        -0.985069   0.531893   4.751492  \n1         0.082733  -0.231481   0.454390  \n2         0.449221  -0.586420  -4.736147  \n3        -0.434290   1.344650   0.429241  \n4         0.812631   0.123457  -0.223359  \n...            ...        ...        ...  \n1558075  -0.723536  -0.353909  -0.914749  \n1558076   0.691407  -0.613169  -0.515772  \n1558077   0.716855   1.628601   0.928389  \n1558078  -0.914914   0.364198   0.211424  \n1558079  -0.418516  -1.453704  -1.561381  \n\n[1558080 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>subject</th>\n      <th>step</th>\n      <th>sensor_00</th>\n      <th>sensor_01</th>\n      <th>sensor_02</th>\n      <th>sensor_03</th>\n      <th>sensor_04</th>\n      <th>sensor_05</th>\n      <th>sensor_06</th>\n      <th>sensor_07</th>\n      <th>sensor_08</th>\n      <th>sensor_09</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>47</td>\n      <td>0</td>\n      <td>-0.196291</td>\n      <td>0.112395</td>\n      <td>1.000000</td>\n      <td>0.329204</td>\n      <td>-1.004660</td>\n      <td>-0.131638</td>\n      <td>-0.127505</td>\n      <td>0.368702</td>\n      <td>-0.1</td>\n      <td>-0.963873</td>\n      <td>-0.985069</td>\n      <td>0.531893</td>\n      <td>4.751492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>47</td>\n      <td>1</td>\n      <td>-0.447450</td>\n      <td>0.134454</td>\n      <td>1.000000</td>\n      <td>-0.658407</td>\n      <td>0.162495</td>\n      <td>0.340314</td>\n      <td>-0.209472</td>\n      <td>-0.867176</td>\n      <td>0.2</td>\n      <td>-0.301301</td>\n      <td>0.082733</td>\n      <td>-0.231481</td>\n      <td>0.454390</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>47</td>\n      <td>2</td>\n      <td>0.326893</td>\n      <td>-0.694328</td>\n      <td>1.000000</td>\n      <td>0.330088</td>\n      <td>0.473678</td>\n      <td>1.280479</td>\n      <td>-0.094718</td>\n      <td>0.535878</td>\n      <td>1.4</td>\n      <td>1.002168</td>\n      <td>0.449221</td>\n      <td>-0.586420</td>\n      <td>-4.736147</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>47</td>\n      <td>3</td>\n      <td>0.523184</td>\n      <td>0.751050</td>\n      <td>1.000000</td>\n      <td>0.976991</td>\n      <td>-0.563287</td>\n      <td>-0.720269</td>\n      <td>0.793260</td>\n      <td>0.951145</td>\n      <td>-0.3</td>\n      <td>-0.995665</td>\n      <td>-0.434290</td>\n      <td>1.344650</td>\n      <td>0.429241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>47</td>\n      <td>4</td>\n      <td>0.272025</td>\n      <td>1.074580</td>\n      <td>1.000000</td>\n      <td>-0.136283</td>\n      <td>0.398579</td>\n      <td>0.044877</td>\n      <td>0.560109</td>\n      <td>-0.541985</td>\n      <td>-0.9</td>\n      <td>1.055636</td>\n      <td>0.812631</td>\n      <td>0.123457</td>\n      <td>-0.223359</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1558075</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>55</td>\n      <td>-0.282844</td>\n      <td>-1.217437</td>\n      <td>-1.666153</td>\n      <td>0.586726</td>\n      <td>-0.930698</td>\n      <td>-0.451010</td>\n      <td>-0.651184</td>\n      <td>0.368702</td>\n      <td>0.4</td>\n      <td>0.008671</td>\n      <td>-0.723536</td>\n      <td>-0.353909</td>\n      <td>-0.914749</td>\n    </tr>\n    <tr>\n      <th>1558076</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>56</td>\n      <td>0.130603</td>\n      <td>0.349790</td>\n      <td>-1.666153</td>\n      <td>-0.324779</td>\n      <td>0.775324</td>\n      <td>-0.332835</td>\n      <td>0.099271</td>\n      <td>0.122137</td>\n      <td>-0.2</td>\n      <td>0.644509</td>\n      <td>0.691407</td>\n      <td>-0.613169</td>\n      <td>-0.515772</td>\n    </tr>\n    <tr>\n      <th>1558077</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>57</td>\n      <td>-0.579598</td>\n      <td>0.429622</td>\n      <td>-1.666153</td>\n      <td>0.319469</td>\n      <td>0.308861</td>\n      <td>0.282723</td>\n      <td>-0.512750</td>\n      <td>0.012214</td>\n      <td>-1.6</td>\n      <td>-0.424133</td>\n      <td>0.716855</td>\n      <td>1.628601</td>\n      <td>0.928389</td>\n    </tr>\n    <tr>\n      <th>1558078</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>58</td>\n      <td>1.278980</td>\n      <td>1.711134</td>\n      <td>-1.522820</td>\n      <td>0.802655</td>\n      <td>-0.460541</td>\n      <td>-0.055348</td>\n      <td>2.405282</td>\n      <td>0.043511</td>\n      <td>1.9</td>\n      <td>0.283960</td>\n      <td>-0.914914</td>\n      <td>0.364198</td>\n      <td>0.211424</td>\n    </tr>\n    <tr>\n      <th>1558079</th>\n      <td>25967</td>\n      <td>327</td>\n      <td>59</td>\n      <td>-1.136012</td>\n      <td>-3.702731</td>\n      <td>-1.332820</td>\n      <td>-0.766372</td>\n      <td>-0.430027</td>\n      <td>-0.091997</td>\n      <td>-2.512750</td>\n      <td>-0.022901</td>\n      <td>-1.1</td>\n      <td>-0.653902</td>\n      <td>-0.418516</td>\n      <td>-1.453704</td>\n      <td>-1.561381</td>\n    </tr>\n  </tbody>\n</table>\n<p>1558080 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5fa550",
   "metadata": {},
   "outputs": [],
   "source": [
    "Window = 60\n",
    "y = train_labels['state'].to_numpy()\n",
    "train = train.loc[:, ['sensor_00', 'sensor_01', 'sensor_02', 'sensor_03', 'sensor_04', 'sensor_05', 'sensor_06', 'sensor_07', 'sensor_08', 'sensor_09', 'sensor_10', 'sensor_11', 'sensor_12']]\n",
    "test = test.loc[:, ['sensor_00', 'sensor_01', 'sensor_02', 'sensor_03', 'sensor_04', 'sensor_05', 'sensor_06', 'sensor_07', 'sensor_08', 'sensor_09', 'sensor_10', 'sensor_11', 'sensor_12']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(25968,)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "012db34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train)\n",
    "X_train = sc.transform(train)\n",
    "X_test = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84864509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.07399419,  0.02575496,  0.52994079, ..., -0.51394323,\n         0.11817284,  0.12176644],\n       [-0.16846171,  0.03076355,  0.52994079, ...,  0.0429771 ,\n        -0.05024707,  0.01191576],\n       [ 0.1227889 , -0.15741634,  0.52994079, ...,  0.23412207,\n        -0.12855551, -0.12077463],\n       ...,\n       [-0.21816616,  0.09778326, -0.63026452, ...,  0.37370821,\n         0.36013458,  0.024033  ],\n       [ 0.48089345,  0.38875849, -0.56789148, ..., -0.47735358,\n         0.08117493,  0.00570458],\n       [-0.42744803, -0.84049264, -0.48521092, ..., -0.21845335,\n        -0.31990049, -0.03961523]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f682763",
   "metadata": {},
   "source": [
    "## 整理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb254ea5",
   "metadata": {},
   "source": [
    "準備進入訓練的資料格式：設定 sequence\n",
    "sequence 設為 60 ，代表過去 60 秒的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c419e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.copy()\n",
    "X_train = X_train.reshape(-1, Window, X_train.shape[-1])\n",
    "X_test = X_test.reshape(-1, Window, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee0db4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25968,) (25968, 60, 13) (12218, 60, 13)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "064647df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-7.39941949e-02,  2.57549585e-02,  5.29940790e-01, ...,\n         -5.13943234e-01,  1.18172836e-01,  1.21766440e-01],\n        [-1.68461709e-01,  3.07635486e-02,  5.29940790e-01, ...,\n          4.29771001e-02, -5.02470657e-02,  1.19157570e-02],\n        [ 1.22788905e-01, -1.57416339e-01,  5.29940790e-01, ...,\n          2.34122074e-01, -1.28555511e-01, -1.20774628e-01],\n        ...,\n        [ 3.66369758e-01, -5.87678086e-01,  3.84887188e-01, ...,\n          9.43643246e-01, -6.54924449e-01, -1.84052370e-01],\n        [-2.11943389e+00,  8.23074813e-01,  3.84887188e-01, ...,\n          2.32894843e-01,  2.98395750e-01, -6.83245867e-01],\n        [ 2.83357057e+00, -4.06891831e-01,  3.84887188e-01, ...,\n         -8.30538459e-01,  3.22682717e-01, -1.29474183e+00]],\n\n       [[-2.50428001e+00, -3.19630807e-02, -9.20148225e-01, ...,\n          6.09078938e-01,  3.37209501e-01, -3.17886919e-01],\n        [ 6.14310650e-01,  1.33320395e-01, -8.31077714e-01, ...,\n          6.16109001e-01,  5.27419578e-01,  2.16022071e+00],\n        [ 7.00639425e-01, -4.86552265e-01, -7.75318126e-01, ...,\n         -1.00100232e+00, -7.73862492e-01, -9.18420696e-01],\n        ...,\n        [ 4.24794282e-01,  1.23541719e-01, -4.85210922e-01, ...,\n          1.90926582e-01,  2.17817495e-01, -4.89340139e-05],\n        [-2.63244336e-02, -9.57522458e-04, -4.85210922e-01, ...,\n          2.21607350e-01, -9.22385506e-02,  2.80602869e-03],\n        [-3.88232125e-02, -1.77927709e-01, -3.40882588e-01, ...,\n         -1.63239007e-02, -1.67823223e-01, -2.64237341e-03]],\n\n       [[-6.55332746e-01,  3.55336345e-02, -3.40157320e-01, ...,\n          3.56981505e-01, -1.74178691e-01,  4.08095478e-03],\n        [ 1.27965262e+00, -3.80179350e-01, -3.40157320e-01, ...,\n          1.88214554e-01,  7.11877691e-02,  5.72183826e-04],\n        [-2.37931666e-01,  5.27329489e-01, -3.40157320e-01, ...,\n         -3.63781706e-01,  1.65384884e-01,  4.38606530e-03],\n        ...,\n        [-3.20772410e-01, -1.67672024e-01, -4.85210922e-01, ...,\n          6.36733615e-02, -9.65511896e-02, -2.03215238e-03],\n        [ 2.19266661e-02, -9.85057787e-02, -4.85210922e-01, ...,\n          2.92453411e-01, -7.02213937e-02, -7.54593531e-03],\n        [ 2.80622322e-01,  5.84300468e-02, -4.85210922e-01, ...,\n         -1.82666693e-01,  4.98515551e-02,  1.47661857e-03]],\n\n       ...,\n\n       [[-3.67885276e-02,  4.06169307e-01, -1.95103717e-01, ...,\n          1.15540873e+00,  2.02155806e-01,  1.64270339e-02],\n        [-3.23969772e-01, -4.24572696e-02, -1.95103717e-01, ...,\n         -1.04247060e+00, -1.64191527e-01, -1.02592396e-02],\n        [ 3.49220271e-01, -4.26926192e-01, -3.29278299e-01, ...,\n          1.12366739e+00, -1.08127221e-01,  3.26369446e-03],\n        ...,\n        [-5.65225271e-01, -9.96983002e-02, -2.33542922e-01, ...,\n         -1.32177922e+00, -1.50118706e-01,  1.85301172e-02],\n        [ 2.34696576e-01,  2.48756473e-01, -3.40157320e-01, ...,\n          3.60996519e-01, -4.23027307e-02, -3.49405011e-02],\n        [ 1.77725398e-01,  1.13763043e-01, -3.40157320e-01, ...,\n          7.37771504e-01,  5.13119775e-01,  4.63714519e-02]],\n\n       [[-1.34453404e-01,  1.40714028e-01, -1.95103717e-01, ...,\n          1.28594971e+00, -4.75232937e-02, -2.31497055e-01],\n        [-6.03302946e-01,  3.37241566e-01, -1.95103717e-01, ...,\n         -5.45623968e-01, -1.25682198e-02, -2.50893367e-01],\n        [-1.11781201e-01, -6.03657873e-01, -1.95103717e-01, ...,\n         -1.54848359e+00, -3.23155667e-02, -5.52832914e-01],\n        ...,\n        [-2.44035721e-01, -2.17280917e-01,  9.47799837e-02, ...,\n          7.64497601e-03,  6.95989021e-02, -3.90503222e-01],\n        [-2.25457331e-02,  1.52607695e-02,  9.47799837e-02, ...,\n          7.38165429e-01, -1.58517003e-01, -2.72207516e-01],\n        [ 2.54752756e-01,  7.82259032e-02,  9.47799837e-02, ...,\n          1.47820071e+00, -3.94294177e-03,  4.97183139e-01]],\n\n       [[-1.18175925e-01, -2.19459003e-02, -6.30264524e-01, ...,\n         -2.02984179e-01,  5.96117381e-02, -9.80157378e-03],\n        [ 1.47495793e-01, -1.01129326e-01, -6.30264524e-01, ...,\n         -2.42755545e-01, -2.82902590e-01, -3.33495677e-02],\n        [-2.08574070e-01,  2.66405791e-01,  2.40057089e-01, ...,\n          2.95483610e-01,  2.35068051e-01,  4.37017349e-02],\n        ...,\n        [-2.18166156e-01,  9.77832553e-02, -6.30264524e-01, ...,\n          3.73708206e-01,  3.60134582e-01,  2.40330033e-02],\n        [ 4.80893453e-01,  3.88758494e-01, -5.67891475e-01, ...,\n         -4.77353577e-01,  8.11749331e-02,  5.70457861e-03],\n        [-4.27448034e-01, -8.40492637e-01, -4.85210922e-01, ...,\n         -2.18453347e-01, -3.19900493e-01, -3.96152301e-02]]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d86d50",
   "metadata": {},
   "source": [
    "## 搭建 LSTM 網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb26608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0196d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DNN_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 60, 13)]     0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_21 (Bidirectiona  (None, 60, 1536)    4804608     ['input_4[0][0]']                \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_22 (Bidirectiona  (None, 60, 1024)    8392704     ['bidirectional_21[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_23 (Bidirectiona  (None, 60, 1024)    2154496     ['input_4[0][0]']                \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 60, 2048)     0           ['bidirectional_22[0][0]',       \n",
      "                                                                  'bidirectional_23[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_24 (Bidirectiona  (None, 60, 768)     7474176     ['concatenate_12[0][0]']         \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_25 (Bidirectiona  (None, 60, 768)     4328448     ['bidirectional_22[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 60, 1536)     0           ['bidirectional_24[0][0]',       \n",
      "                                                                  'bidirectional_25[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_26 (Bidirectiona  (None, 60, 512)     3672064     ['concatenate_13[0][0]']         \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_27 (Bidirectiona  (None, 60, 256)     918528      ['bidirectional_25[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 60, 768)      0           ['bidirectional_26[0][0]',       \n",
      "                                                                  'bidirectional_27[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 60, 5888)     0           ['bidirectional_21[0][0]',       \n",
      "                                                                  'concatenate_12[0][0]',         \n",
      "                                                                  'concatenate_13[0][0]',         \n",
      "                                                                  'concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 60, 128)      753792      ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 60, 128)      0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 7680)         0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            7681        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,506,497\n",
      "Trainable params: 32,506,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    input_layer = Input(shape=(X_train.shape[-2:]))\n",
    "    x1 = Bidirectional(LSTM(768, return_sequences=True))(input_layer)\n",
    "\n",
    "    x21 = Bidirectional(LSTM(512, return_sequences=True))(x1)\n",
    "    x22 = Bidirectional(LSTM(512, return_sequences=True))(input_layer)\n",
    "    l2 = Concatenate(axis=2)([x21, x22])\n",
    "\n",
    "    x31 = Bidirectional(LSTM(384, return_sequences=True))(l2)\n",
    "    x32 = Bidirectional(LSTM(384, return_sequences=True))(x21)\n",
    "    l3 = Concatenate(axis=2)([x31, x32])\n",
    "\n",
    "    x41 = Bidirectional(LSTM(256, return_sequences=True))(l3)\n",
    "    x42 = Bidirectional(LSTM(128, return_sequences=True))(x32)\n",
    "    l4 = Concatenate(axis=2)([x41, x42])\n",
    "\n",
    "    l5 = Concatenate(axis=2)([x1, l2, l3, l4])\n",
    "    x7 = Dense(128, activation='selu')(l5)\n",
    "    x8 = Dropout(0.3)(x7)\n",
    "    f = Flatten()(x8)\n",
    "    output_layer = Dense(units=1, activation=\"sigmoid\")(f)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='DNN_Model')\n",
    "    model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[AUC(name = 'auc')])\n",
    "    return  model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4258179",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 Epoch 1/30\n",
      "366/366 [==============================] - 113s 260ms/step - loss: 0.7098 - auc: 0.5768 - val_loss: 0.7229 - val_auc: 0.6286 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "366/366 [==============================] - 93s 253ms/step - loss: 0.6130 - auc: 0.7358 - val_loss: 0.6208 - val_auc: 0.7442 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "366/366 [==============================] - 94s 256ms/step - loss: 0.5100 - auc: 0.8322 - val_loss: 0.4823 - val_auc: 0.8590 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "366/366 [==============================] - 94s 256ms/step - loss: 0.3988 - auc: 0.9019 - val_loss: 0.4518 - val_auc: 0.8939 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "366/366 [==============================] - 94s 258ms/step - loss: 0.3332 - auc: 0.9327 - val_loss: 0.3845 - val_auc: 0.9166 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "366/366 [==============================] - 95s 258ms/step - loss: 0.2963 - auc: 0.9472 - val_loss: 0.3405 - val_auc: 0.9324 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.2606 - auc: 0.9590 - val_loss: 0.3574 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "366/366 [==============================] - 95s 260ms/step - loss: 0.2423 - auc: 0.9649 - val_loss: 0.3633 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.2105 - auc: 0.9732 - val_loss: 0.3984 - val_auc: 0.9273 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.1947 - auc: 0.9769 - val_loss: 0.4696 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.1343 - auc: 0.9884 - val_loss: 0.3925 - val_auc: 0.9353 - lr: 7.0000e-04\n",
      "Epoch 12/30\n",
      "366/366 [==============================] - 95s 260ms/step - loss: 0.1089 - auc: 0.9923 - val_loss: 0.4213 - val_auc: 0.9346 - lr: 7.0000e-04\n",
      "Epoch 13/30\n",
      "366/366 [==============================] - 95s 258ms/step - loss: 0.1006 - auc: 0.9931 - val_loss: 0.4485 - val_auc: 0.9330 - lr: 7.0000e-04\n",
      "Epoch 14/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.0876 - auc: 0.9949 - val_loss: 0.5084 - val_auc: 0.9312 - lr: 7.0000e-04\n",
      "Epoch 15/30\n",
      "366/366 [==============================] - 95s 259ms/step - loss: 0.0697 - auc: 0.9964 - val_loss: 0.5230 - val_auc: 0.9302 - lr: 7.0000e-04\n",
      "Epoch 16/30\n",
      "366/366 [==============================] - 94s 258ms/step - loss: 0.0421 - auc: 0.9986 - val_loss: 0.5543 - val_auc: 0.9352 - lr: 4.9000e-04\n",
      "Epoch 17/30\n",
      "366/366 [==============================] - 94s 258ms/step - loss: 0.0303 - auc: 0.9993 - val_loss: 0.6552 - val_auc: 0.9274 - lr: 4.9000e-04\n",
      "Epoch 18/30\n",
      "366/366 [==============================] - 94s 258ms/step - loss: 0.0260 - auc: 0.9994 - val_loss: 0.6796 - val_auc: 0.9282 - lr: 4.9000e-04\n",
      "Epoch 19/30\n",
      "366/366 [==============================] - 94s 258ms/step - loss: 0.0257 - auc: 0.9995 - val_loss: 0.6951 - val_auc: 0.9204 - lr: 4.9000e-04\n",
      "Epoch 20/30\n",
      "366/366 [==============================] - 94s 257ms/step - loss: 0.0161 - auc: 0.9997 - val_loss: 0.6718 - val_auc: 0.9300 - lr: 3.4300e-04\n",
      "Epoch 21/30\n",
      "366/366 [==============================] - 95s 260ms/step - loss: 0.0058 - auc: 1.0000 - val_loss: 0.7597 - val_auc: 0.9283 - lr: 3.4300e-04\n",
      "auc: 0.93731\n",
      "Fold: 2 Epoch 1/30\n",
      "366/366 [==============================] - 115s 268ms/step - loss: 0.7148 - auc: 0.5480 - val_loss: 0.6883 - val_auc: 0.6124 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "137/366 [==========>...................] - ETA: 56s - loss: 0.6741 - auc: 0.6523"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "test_preds = []\n",
    "auc = []\n",
    "nfold = 10\n",
    "\n",
    "col, row = 0, 0\n",
    "kf = GroupKFold(n_splits=nfold)\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train, y_train, groups.unique())):\n",
    "    print(f\"Fold: {fold+1}\", end=' ')\n",
    "    X_train_part, X_valid = X_train[train_idx], X_train[test_idx]\n",
    "    y_train_part, y_valid = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "    model = get_model()\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_auc\", mode='max', factor=0.7, patience=4, verbose=False)\n",
    "    es = EarlyStopping(monitor='val_auc',mode='max', patience=10, verbose=False,restore_best_weights=True)\n",
    "    history = model.fit(X_train_part, y_train_part, validation_data=(X_valid, y_valid), epochs=30, batch_size=64,\n",
    "                        callbacks=[es,lr], verbose=1)\n",
    "\n",
    "    y_pred = model.predict(X_valid).squeeze()\n",
    "    auc_score = roc_auc_score(y_valid, y_pred)\n",
    "    print(f'auc: {round(auc_score, 5)}')\n",
    "    test_preds.append(model.predict(X_test).squeeze())\n",
    "    auc.append(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fcd935",
   "metadata": {},
   "source": [
    "## 視覺化結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "plt.plot(epochs, acc, 'go', label='Training Acc')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3bc4c",
   "metadata": {},
   "source": [
    "## 預測真實資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fe815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = (y_pred[:] > 0.5).astype(int)\n",
    "\n",
    "y_pred = np.reshape(y_pred, (-1,))\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['state'])\n",
    "\n",
    "y_pred_df.insert(0, \"sequence\", np.arange(25968, 25968+y_pred_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}