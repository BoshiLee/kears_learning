{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c4d65",
   "metadata": {},
   "source": [
    "In this competition, you'll classify 60-second sequences of sensor data, indicating whether a subject was in either of two activity states for the duration of the sequence.\n",
    "\n",
    "在本次競賽中，您將對 60 秒的感測器資料序列進行分類，找出受試者在序列持續時間內處於兩種活動狀態的其中一種。\n",
    "\n",
    "## Files and Field Descriptions\n",
    "- train.csv - the training set, comprising ~26,000 60-second recordings of thirteen biological sensors for almost one thousand experimental participants\n",
    "    - sequence - a unique id for each sequence\n",
    "    - subject - a unique id for the subject in the experiment\n",
    "    - step - time step of the recording, in one second intervals\n",
    "    - sensor_00 - sensor_12 - the value for each of the thirteen sensors at that time step\n",
    "- train_labels.csv - the class label for each sequence.\n",
    "    - sequence - the unique id for each sequence.\n",
    "    - state - the state associated to each sequence. This is the target which you are trying to predict.\n",
    "- test.csv - the test set. For each of the ~12,000 sequences, you should predict a value for that sequence's state.\n",
    "- sample_submission.csv - a sample submission file in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849ef78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe9b26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a150d70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539b752",
   "metadata": {},
   "source": [
    "由上表與題目提示可得知，每一秒會記錄一列，每 60 列代表一個 `sequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a76d87",
   "metadata": {},
   "source": [
    "確認資料是否有缺漏，本題的資料都很完美，沒有有缺漏的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b4db6",
   "metadata": {},
   "source": [
    "## 特徵工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857522f",
   "metadata": {},
   "source": [
    "萃取需要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79acd11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "groups = train['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242d2e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fa550",
   "metadata": {},
   "outputs": [],
   "source": [
    "Window = 60\n",
    "y = train_labels['state'].to_numpy()\n",
    "train = train.loc[:, ['sensor_00', 'sensor_01', 'sensor_02', 'sensor_03', 'sensor_04', 'sensor_05', 'sensor_06', 'sensor_07', 'sensor_08', 'sensor_09', 'sensor_10', 'sensor_11', 'sensor_12']]\n",
    "test = test.loc[:, ['sensor_00', 'sensor_01', 'sensor_02', 'sensor_03', 'sensor_04', 'sensor_05', 'sensor_06', 'sensor_07', 'sensor_08', 'sensor_09', 'sensor_10', 'sensor_11', 'sensor_12']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a0200",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd4cfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012db34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train)\n",
    "X_train = sc.transform(train)\n",
    "X_test = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84864509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f682763",
   "metadata": {},
   "source": [
    "## 整理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb254ea5",
   "metadata": {},
   "source": [
    "準備進入訓練的資料格式：設定 sequence\n",
    "sequence 設為 60 ，代表過去 60 秒的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.copy()\n",
    "X_train = X_train.reshape(-1, Window, X_train.shape[-1])\n",
    "X_test = X_test.reshape(-1, Window, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0db4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064647df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d86d50",
   "metadata": {},
   "source": [
    "## 搭建 LSTM 網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196d941",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_layer = Input(shape=(X_train.shape[1:]))\n",
    "    conv1 = Conv1D(64, 3, activation='relu')(input_layer)\n",
    "    pool1 = MaxPooling1D(3)(conv1)\n",
    "    d1 = Dropout(0.5)(pool1)\n",
    "\n",
    "    x1 = Bidirectional(LSTM(64, return_sequences=True))(d1)\n",
    "    x21 = Bidirectional(LSTM(32, return_sequences=True))(x1)\n",
    "    x22 = Bidirectional(LSTM(32, return_sequences=True))(d1)\n",
    "    l2 = Concatenate(axis=2)([x21, x22])\n",
    "\n",
    "    x31 = Bidirectional(LSTM(10, return_sequences=True))(l2)\n",
    "    x32 = Bidirectional(LSTM(10, return_sequences=True))(x21)\n",
    "    l3 = Concatenate(axis=2)([x31, x32])\n",
    "\n",
    "    l5 = Concatenate(axis=2)([x1, l2, l3])\n",
    "    x7 = Dense(32, activation='selu')(l5)\n",
    "    x8 = Dropout(0.3)(x7)\n",
    "    f = Flatten()(x8)\n",
    "    output_layer = Dense(units=1, activation=\"sigmoid\")(f)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='DNN_Model')\n",
    "    model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=[AUC(name = 'auc')])\n",
    "    return  model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033709d1",
   "metadata": {},
   "source": [
    "Reson for why add Fallten in last dense\n",
    "\n",
    "An LSTM layer consists of different LSTM cells that are processed sequentially. As seen in the figure below, the first cell takes an input/embedding calculates a hidden state and the next cell uses its input and the hidden state at previous time step to compute its own hidden state. Basically the arrows between the cells also pass the hidden states. <b>If you do return_sequences=False, the lstm layer only outputs the very last hidden state! (h_4 in the figure). So, all those information from all inputs and cells are embedded in a single fixed size information and it can not contain lots of information.</b> This is why, your accuracy is not good when you only use the last hidden state.\n",
    "\n",
    "When you do `return_sequences=True`, lstm layer outputs every hidden state, so the next layers have access to all hidden states and they contain naturally more information. However, the LSTM layer returns a matrix. You can also see this in your model summary. It returns a matrix of size (None, 500, 128). None is basically number of samples in your batch, you can forget about it. 500 is your input size, and 128 is your hidden state size. <b>The dense layer can not process a matrix, it has to be a vector. That why you need to apply flatten and what it does is basically just to open up the 2D matrix and represent it as 1D vector.</b> Therefore, the size of your Flatten layer is 64000 because 500*128 = 64000. And Of course with more hidden states, the accuracy is better as they contain more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833410b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hist(hist, metric='auc', ax=None, fold=0):\n",
    "    if ax==None:\n",
    "        plt.plot(hist.history[metric])\n",
    "        plt.plot(hist.history[\"val_\" + metric])\n",
    "        plt.title(f\"model performance fold {fold}\")\n",
    "        plt.ylabel(\"area_under_curve\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        return\n",
    "    else:\n",
    "        ax.plot(hist.history[metric])\n",
    "        ax.plot(hist.history[\"val_\" + metric])\n",
    "        ax.set_title(f\"model performance fold {fold}\")\n",
    "        ax.set_ylabel(\"area_under_curve\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend([\"train\", \"validation\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4258179",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_model(folds):\n",
    "    test_preds = []\n",
    "    auc = []\n",
    "    nfold = folds\n",
    "    ncols = 5\n",
    "    nrows = round(nfold / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(20, round(nrows*20/ncols)))\n",
    "    kf = GroupKFold(n_splits=nfold)\n",
    "    col, row = 0, 0\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_train, y_train, groups.unique())):\n",
    "        print(f\"Fold: {fold+1}\", end=' ')\n",
    "        X_train_part, X_valid = X_train[train_idx], X_train[test_idx]\n",
    "        y_train_part, y_valid = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "        model = get_model()\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_auc\", mode='max', factor=0.7, patience=4, verbose=False)\n",
    "        es = EarlyStopping(monitor='val_auc',mode='max', patience=10, verbose=False,restore_best_weights=True)\n",
    "        history = model.fit(X_train_part, y_train_part, validation_data=(X_valid, y_valid), epochs=60, batch_size=32,\n",
    "                            callbacks=[es,lr], verbose=1)\n",
    "\n",
    "        y_pred = model.predict(X_valid).squeeze()\n",
    "        auc_score = roc_auc_score(y_valid, y_pred)\n",
    "        print(f'auc: {round(auc_score, 5)}')\n",
    "        test_preds.append(model.predict(X_test).squeeze())\n",
    "        auc.append(auc_score)\n",
    "        \n",
    "        model.save('fold_{}.h5'.format(nfold))\n",
    "        plot_hist(history, metric='auc', ax=axes[row][col], fold=fold+1)\n",
    "        del X_train_part, X_valid, y_train_part, y_valid, model, history\n",
    "\n",
    "        col += 1\n",
    "        if col >= ncols:\n",
    "            row += 1\n",
    "            col = 0\n",
    "    return (test_preds, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b8ad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folds = 4\n",
    "(test_preds, auc) = fit_model(folds)\n",
    "\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3bc4c",
   "metadata": {},
   "source": [
    "## 預測真實資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b639ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the mean AUC for the {folds} folds is : {round(np.mean(auc)*100,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e14ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data['state'] = sum(test_preds)/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.state = (sub_data.state > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60354a78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
