{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\keras_learning\\training_project\\Natural Language Processing with Disaster Tweets\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19496/1163205464.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mcurrent_directory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetcwd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent_directory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtrain\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/train.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/test.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 680\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    931\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    932\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 933\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    934\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    935\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1216\u001B[0m             \u001B[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1217\u001B[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001B[0m\u001B[0;32m   1218\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1219\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\tensor_boshi\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    787\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    788\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 789\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    790\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    791\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/train.csv'"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.columns)\n",
    "train.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "         id     keyword                     location  \\\n2649   8849       smoke                     Roseland   \n620    2021  casualties                          NaN   \n3185  10577   windstorm                          NaN   \n384    1248       blood  The Land of Pleasant Living   \n2271   7574    outbreak         Nashville, Tennessee   \n\n                                                   text  \n2649  @wizkhalifa smoke ??so much you don't gotta do...  \n620   More women children casualties of Afghan viole...  \n3185  Texas Seeks Comment on Rules for Changes to Wi...  \n384            Bitch I'm a monster no good blood sucker  \n2271  Families to sue over Legionnaires: More than 4...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2649</th>\n      <td>8849</td>\n      <td>smoke</td>\n      <td>Roseland</td>\n      <td>@wizkhalifa smoke ??so much you don't gotta do...</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>2021</td>\n      <td>casualties</td>\n      <td>NaN</td>\n      <td>More women children casualties of Afghan viole...</td>\n    </tr>\n    <tr>\n      <th>3185</th>\n      <td>10577</td>\n      <td>windstorm</td>\n      <td>NaN</td>\n      <td>Texas Seeks Comment on Rules for Changes to Wi...</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>1248</td>\n      <td>blood</td>\n      <td>The Land of Pleasant Living</td>\n      <td>Bitch I'm a monster no good blood sucker</td>\n    </tr>\n    <tr>\n      <th>2271</th>\n      <td>7574</td>\n      <td>outbreak</td>\n      <td>Nashville, Tennessee</td>\n      <td>Families to sue over Legionnaires: More than 4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train_label = train.target.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "y_train = train_label.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train.drop(['id', 'keyword', 'location', 'target'], axis=1, inplace=True)\n",
    "test.drop(['id', 'keyword', 'location'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "X_train = train.reshape(-1)\n",
    "X_test = test.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "\n",
    "  #apostrophe\n",
    "  tweet = re.sub(r'\\x89Ûª', \"'\", tweet)\n",
    "  tweet = re.sub(r'\\x89Û÷', \"'\", tweet)\n",
    "\n",
    "  #quotation\n",
    "  tweet = re.sub(r'\\x89ÛÏ', '\"', tweet)\n",
    "  tweet = re.sub(r'\\x89Û\\x9d', '\"', tweet)\n",
    "\n",
    "  #hyphen\n",
    "  tweet = re.sub(r'\\x89ÛÒ', '-', tweet)\n",
    "  tweet = re.sub(r'\\x89ÛÓ', '—', tweet)\n",
    "\n",
    "  #euro\n",
    "  tweet = re.sub(r'\\x89âÂ', '€', tweet)\n",
    "\n",
    "  #ellipsis\n",
    "  tweet = re.sub(r'\\x89Û_', '...', tweet)\n",
    "\n",
    "  #amp\n",
    "  tweet = re.sub(r'&', 'and', tweet)\n",
    "\n",
    "\n",
    "  #bullet\n",
    "  tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r'\\x89Û¢', '', tweet)\n",
    "\n",
    "\n",
    "  #no idea\n",
    "  tweet = re.sub(r'\\x89ã¢', '', tweet)\n",
    "  tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "\n",
    "\n",
    "  #other\n",
    "  tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "  tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)\n",
    "  tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "  tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "  tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "  tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"å£3million\", \"3 million \", tweet)\n",
    "  tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "\n",
    "  return tweet\n",
    "\n",
    "def find_URL(text):\n",
    "  url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "  return url.findall(text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'This is a website.',text)\n",
    "\n",
    "def remove_html(text):\n",
    "  html=re.compile(r'<.*?>')\n",
    "  return html.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    r = clean_tweet(input_data)\n",
    "    r = remove_URL(r)\n",
    "    r = remove_html(r)\n",
    "    r = remove_emoji(r)\n",
    "    r = str.lower(r)\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "all_tweets = np.append(X_train, X_test)\n",
    "def normalization(tweets):\n",
    "    result = []\n",
    "    for tweet in tweets:\n",
    "        result.append(custom_standardization(tweet))\n",
    "    return result\n",
    "\n",
    "all_tweets = normalization(all_tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "max_len = 500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading models from TensorFlow Hub"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "'our deeds are the reason of this #earthquake may allah forgive us all'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101  2256 15616  2024  1996  3114  1997  2023  1001  8372  2089 16455]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = [all_tweets[0]]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.8805216   0.8859627   0.02324418  0.346368    0.22012922  0.54245526\n",
      "  0.9885263  -0.97328836 -0.44442183 -0.9884246   0.15767492 -0.986612  ]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[ 0.04167694 -0.5527509  -0.39509642 ... -0.70465016  0.02087686\n",
      "   1.359921  ]\n",
      " [-0.02986103  0.20303433 -0.74737203 ... -0.62841207 -0.22217065\n",
      "   0.3419122 ]\n",
      " [-0.5731175  -0.8957891  -0.31389296 ... -0.291898    0.57954067\n",
      "   1.3041601 ]\n",
      " ...\n",
      " [-0.5826614  -0.20335156 -0.49349603 ...  0.0648779  -0.07748289\n",
      "   0.6788095 ]\n",
      " [-0.5776433  -0.11583461 -0.697853   ... -0.740928   -0.07606461\n",
      "   0.75299025]\n",
      " [ 0.17244081 -0.7967615   0.7065049  ...  0.7029192   1.3446757\n",
      "   0.69009024]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "## Spilt Data to train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).cache()\n",
    "train_ds = train_ds.batch(batch_size=batch_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "val_ds = val_ds.batch(batch_size=batch_size).cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras.metrics import BinaryAccuracy\n",
    "\n",
    "def build_classifier_model():\n",
    "    text_input = Input(shape=(), dtype='string', name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = Dropout(0.1)(net)\n",
    "    net = Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "\n",
    "    model = Model(text_input, net)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "\n",
    "    model.compile(loss=losses.binary_crossentropy, optimizer=optimizer, metrics=[BinaryAccuracy()])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "classifier_model = build_classifier_model()\n",
    "# bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "# print(bert_raw_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'sequence_output':  28763649    ['preprocessing[0][0]',          \n",
      "                                 (None, 128, 512),                'preprocessing[0][1]',          \n",
      "                                 'pooled_output': (               'preprocessing[0][2]']          \n",
      "                                None, 512),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                512),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)]}                                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.5377 - binary_accuracy: 0.7286"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'WarmUp' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_10520/3963182991.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_binary_accuracy'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'max'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrestore_best_weights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m history = classifier_model.fit(\n\u001B[0m\u001B[0;32m      7\u001B[0m                             \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_ds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m                             \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_ds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, current, values, finalize)\u001B[0m\n\u001B[0;32m    893\u001B[0m         \u001B[0mvalue_base\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcurrent\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_seen_so_far\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    894\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mk\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 895\u001B[1;33m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mv\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mvalue_base\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue_base\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    896\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    897\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mv\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mvalue_base\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'WarmUp' and 'int'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor=\"val_binary_accuracy\", mode='max', factor=0.7, patience=4, verbose=False)\n",
    "es = EarlyStopping(monitor='val_binary_accuracy',mode='max', patience=10, verbose=False,restore_best_weights=True)\n",
    "\n",
    "history = classifier_model.fit(\n",
    "                            x=train_ds,\n",
    "                            validation_data=val_ds,\n",
    "                            epochs=epochs,\n",
    "                            callbacks=[es,lr]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(X_test)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_hist(history_dict):\n",
    "    history_dict = history.history\n",
    "    print(history_dict.keys())\n",
    "\n",
    "    acc = history_dict['binary_accuracy']\n",
    "    val_acc = history_dict['val_binary_accuracy']\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    # r is for \"solid red line\"\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    # b is for \"solid blue line\"\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_hist(hist=history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = classifier_model.predict(X_test).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_data = pd.read_csv(\"data/sample_submission.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_data.target = (y_pred > 0.5).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_data.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}