{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\boshi\\GitHub\\kears_learning\\training_project\\Natural Language Processing with Disaster Tweets\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.columns)\n",
    "train.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_label = train.target.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "y_train = train_label.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train.drop(['id', 'keyword', 'location', 'target'], axis=1, inplace=True)\n",
    "test.drop(['id', 'keyword', 'location'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "X_train = train.reshape(-1)\n",
    "X_test = test.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spilt train and valid data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "\n",
    "  #apostrophe\n",
    "  tweet = re.sub(r'\\x89Ûª', \"'\", tweet)\n",
    "  tweet = re.sub(r'\\x89Û÷', \"'\", tweet)\n",
    "\n",
    "  #quotation\n",
    "  tweet = re.sub(r'\\x89ÛÏ', '\"', tweet)\n",
    "  tweet = re.sub(r'\\x89Û\\x9d', '\"', tweet)\n",
    "\n",
    "  #hyphen\n",
    "  tweet = re.sub(r'\\x89ÛÒ', '-', tweet)\n",
    "  tweet = re.sub(r'\\x89ÛÓ', '—', tweet)\n",
    "\n",
    "  #euro\n",
    "  tweet = re.sub(r'\\x89âÂ', '€', tweet)\n",
    "\n",
    "  #ellipsis\n",
    "  tweet = re.sub(r'\\x89Û_', '...', tweet)\n",
    "\n",
    "  #amp\n",
    "  tweet = re.sub(r'&', 'and', tweet)\n",
    "\n",
    "\n",
    "  #bullet\n",
    "  tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r'\\x89Û¢', '', tweet)\n",
    "\n",
    "\n",
    "  #no idea\n",
    "  tweet = re.sub(r'\\x89ã¢', '', tweet)\n",
    "  tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "\n",
    "\n",
    "  #other\n",
    "  tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "  tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)\n",
    "  tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "  tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "  tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "  tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"å£3million\", \"3 million \", tweet)\n",
    "  tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "\n",
    "  return tweet\n",
    "\n",
    "def find_URL(text):\n",
    "  url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "  return url.findall(text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'This is a website.',text)\n",
    "\n",
    "def remove_html(text):\n",
    "  html=re.compile(r'<.*?>')\n",
    "  return html.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    r = clean_tweet(input_data)\n",
    "    r = remove_URL(r)\n",
    "    r = remove_html(r)\n",
    "    r = remove_emoji(r)\n",
    "    r = str.lower(r)\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "all_tweets = np.append(X_train, X_test)\n",
    "def normalization(tweets):\n",
    "    result = []\n",
    "    for tweet in tweets:\n",
    "        result.append(custom_standardization(tweet))\n",
    "    return result\n",
    "\n",
    "all_tweets = normalization(all_tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "max_len = 500"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's make a text-only dataset (no labels):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Let's call `adapt`:\n",
    "vectorize_layer.adapt(all_tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apply it to the text dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from keras.metrics import AUC\n",
    "def build_model():\n",
    "\n",
    "    text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
    "    x = vectorize_layer(text_input)\n",
    "    x = Embedding(max_features + 1, embedding_dim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x1 = Bidirectional(LSTM(units=512, return_sequences=True))(x)\n",
    "    x2 = Bidirectional(LSTM(units=256, return_sequences=True))(x1)\n",
    "\n",
    "    z2 = Bidirectional(GRU(units=512, return_sequences=True))(x)\n",
    "    z3 = Bidirectional(GRU(units=256, return_sequences=True))(z2)\n",
    "    c = Concatenate(axis=2)([x2, z3])\n",
    "\n",
    "    x3 = Bidirectional(LSTM(units=128, return_sequences=True))(c)\n",
    "    # Conv1D + global max pooling\n",
    "\n",
    "    x = GlobalMaxPooling1D()(x3)\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    predictions = Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "    model = tf.keras.Model(text_input, predictions)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[AUC(name = 'auc')])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 500)         0           ['text[0][0]']                   \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 500, 128)     2560128     ['text_vectorization[0][0]']     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500, 128)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 500, 1024)    2625536     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 500, 1024)   1972224     ['dropout[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 500, 512)    2623488     ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 500, 512)    1969152     ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 500, 1024)    0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 500, 256)    1180672     ['concatenate[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 256)         0           ['bidirectional_4[0][0]']        \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          32896       ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1)            129         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,964,225\n",
      "Trainable params: 12,964,225\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "48/48 [==============================] - 11s 142ms/step - loss: 0.6956 - auc: 0.5965 - val_loss: 0.5692 - val_auc: 0.7988 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 0.4536 - auc: 0.8614 - val_loss: 0.5378 - val_auc: 0.8543 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 0.2764 - auc: 0.9441 - val_loss: 0.4698 - val_auc: 0.8494 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 0.1805 - auc: 0.9741 - val_loss: 0.6359 - val_auc: 0.8421 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 0.1240 - auc: 0.9879 - val_loss: 0.6436 - val_auc: 0.8333 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "48/48 [==============================] - 5s 113ms/step - loss: 0.0976 - auc: 0.9927 - val_loss: 0.6388 - val_auc: 0.8311 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 0.0705 - auc: 0.9959 - val_loss: 0.7590 - val_auc: 0.8308 - lr: 7.0000e-04\n",
      "Epoch 8/60\n",
      "26/48 [===============>..............] - ETA: 2s - loss: 0.0695 - auc: 0.9963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2548/3775774586.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_auc'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'max'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrestore_best_weights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=60, batch_size=128,\n\u001B[0m\u001B[0;32m      7\u001B[0m                     callbacks=[es,lr])\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import *\n",
    "#\n",
    "# lr = ReduceLROnPlateau(monitor=\"val_auc\", mode='max', factor=0.7, patience=4, verbose=False)\n",
    "# es = EarlyStopping(monitor='val_auc',mode='max', patience=10, verbose=False,restore_best_weights=True)\n",
    "#\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=60, batch_size=128,\n",
    "#                     callbacks=[es,lr])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def plot_hist(hist, metric='auc', ax=None, fold=0):\n",
    "    if ax==None:\n",
    "        plt.plot(hist.history[metric])\n",
    "        plt.plot(hist.history[\"val_\" + metric])\n",
    "        plt.title(f\"model performance\")\n",
    "        plt.ylabel(\"area_under_curve\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        return\n",
    "    else:\n",
    "        ax.plot(hist.history[metric])\n",
    "        ax.plot(hist.history[\"val_\" + metric])\n",
    "        ax.set_title(f\"model performance fold {fold}\")\n",
    "        ax.set_ylabel(\"area_under_curve\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend([\"train\", \"validation\"], loc=\"upper left\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 "
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Qr: stream did not block host until done; was already in an error state [Op:Qr]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8856/4287321019.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[0mfolds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m \u001B[1;33m(\u001B[0m\u001B[0mtest_preds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mauc\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfit_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfolds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8856/4287321019.py\u001B[0m in \u001B[0;36mfit_model\u001B[1;34m(nfold, epochs, batch_size, verbose)\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mlr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mReduceLROnPlateau\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"val_auc\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'max'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfactor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.7\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_auc'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'max'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrestore_best_weights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         history = model.fit(X_train_part, y_train_part, validation_data=(X_valid, y_valid), epochs=epochs, batch_size=batch_size,\n\u001B[0;32m     27\u001B[0m                             callbacks=[es,lr], verbose=verbose)\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8856/2883157562.py\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mx1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBidirectional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m512\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_sequences\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     \u001B[0mx2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBidirectional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_sequences\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\layers\\wrappers.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    589\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 590\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBidirectional\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    591\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m     \u001B[1;31m# Applies the same workaround as in `RNN.__call__`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\boshi_intretech\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, shape, dtype, **kwargs)\u001B[0m\n\u001B[0;32m    619\u001B[0m     \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_random_generator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom_normal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat_shape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    620\u001B[0m     \u001B[1;31m# Compute the qr factorization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 621\u001B[1;33m     \u001B[0mq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mqr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfull_matrices\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    622\u001B[0m     \u001B[1;31m# Make Q uniform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    623\u001B[0m     \u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor_diag_part\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Qr: stream did not block host until done; was already in an error state [Op:Qr]"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x288 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import *\n",
    "import gc\n",
    "\n",
    "\n",
    "def fit_model(nfold, epochs=60, batch_size=32, verbose=False):\n",
    "    test_preds = []\n",
    "    auc = []\n",
    "    ncols = 5 if nfold > 5 else nfold\n",
    "    nrows = int(round(nfold / ncols))\n",
    "\n",
    "    col, row = 0, 0\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(16, round(nrows*16/ncols)))\n",
    "\n",
    "    kf = KFold(n_splits=nfold)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "        print(f\"Fold: {fold+1}\", end=' ')\n",
    "        X_train_part, X_valid = X_train[train_idx], X_train[test_idx]\n",
    "        y_train_part, y_valid = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_auc\", mode='max', factor=0.7, patience=4, verbose=False)\n",
    "        es = EarlyStopping(monitor='val_auc',mode='max', patience=10, verbose=False,restore_best_weights=True)\n",
    "        model = build_model()\n",
    "        history = model.fit(X_train_part, y_train_part, validation_data=(X_valid, y_valid), epochs=epochs, batch_size=batch_size,\n",
    "                            callbacks=[es,lr], verbose=verbose)\n",
    "\n",
    "        y_pred = model.predict(X_valid).squeeze()\n",
    "        auc_score = roc_auc_score(y_valid, y_pred)\n",
    "        print(f'auc: {round(auc_score, 5)}')\n",
    "        test_preds.append(model.predict(X_test).squeeze())\n",
    "        auc.append(auc_score)\n",
    "\n",
    "        plot_hist(history, metric='auc', ax=axes[col] if nrows <= 1 else axes[row][col], fold=fold+1)\n",
    "        del X_train_part, X_valid, y_train_part, y_valid, history, model\n",
    "        gc.collect()\n",
    "\n",
    "        col += 1\n",
    "        if col >= ncols:\n",
    "            row += 1\n",
    "            col = 0\n",
    "    return test_preds, auc\n",
    "\n",
    "folds = 4\n",
    "(test_preds, auc) = fit_model(folds, epochs=15, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}